{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as v1\n",
    "v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from scipy.stats import zscore\n",
    "\n",
    "def srcprt_range(prt):\n",
    "\n",
    "    if(prt['prt_src'] < 5000):\n",
    "        return 1\n",
    "    if(prt['prt_src'] < 10000):\n",
    "        return 2\n",
    "    if(prt['prt_src'] < 15000):\n",
    "        return 3\n",
    "    if(prt['prt_src'] < 20000):\n",
    "        return 4\n",
    "    if(prt['prt_src'] < 25000):\n",
    "        return 5\n",
    "    if(prt['prt_src'] < 30000):\n",
    "        return 6\n",
    "    if(prt['prt_src'] < 35000):\n",
    "        return 7\n",
    "    if(prt['prt_src'] < 40000):\n",
    "        return 8\n",
    "    if(prt['prt_src'] < 45000):\n",
    "        return 9\n",
    "    if(prt['prt_src'] < 50000):\n",
    "        return 10\n",
    "    if(prt['prt_src'] < 55000):\n",
    "        return 11\n",
    "    if(prt['prt_src'] < 60000):\n",
    "        return 12\n",
    "    return 13\n",
    "\n",
    "def dstprt_range(prt):\n",
    "\n",
    "    if(prt['prt_dst'] < 5000):\n",
    "        return 1\n",
    "    if(prt['prt_dst'] < 10000):\n",
    "        return 2\n",
    "    if(prt['prt_dst'] < 15000):\n",
    "        return 3\n",
    "    if(prt['prt_dst'] < 20000):\n",
    "        return 4\n",
    "    if(prt['prt_dst'] < 25000):\n",
    "        return 5\n",
    "    if(prt['prt_dst'] < 30000):\n",
    "        return 6\n",
    "    if(prt['prt_dst'] < 35000):\n",
    "        return 7\n",
    "    if(prt['prt_dst'] < 40000):\n",
    "        return 8\n",
    "    if(prt['prt_dst'] < 45000):\n",
    "        return 9\n",
    "    if(prt['prt_dst'] < 50000):\n",
    "        return 10\n",
    "    if(prt['prt_dst'] < 55000):\n",
    "        return 11\n",
    "    if(prt['prt_dst'] < 60000):\n",
    "        return 12\n",
    "    return 13\n",
    "\n",
    "def def_model(input_dim, outputlayer_neurons):\n",
    "    \n",
    "    # Build neural network\n",
    "    model = Sequential()\n",
    "    model.add(Dense(50, input_dim=input_dim, activation='relu')) # Hidden 1\n",
    "    model.add(Dense(25, activation='relu')) # Hidden 2\n",
    "    model.add(Dense(outputlayer_neurons,activation='softmax')) # Output\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "    \n",
    "    return model\n",
    "\n",
    "        \n",
    "def train_model(train_dataframe, classification_type):\n",
    "\n",
    "    if verbose:\n",
    "        print(f'Test train splitting finished')\n",
    "\n",
    "    x_columns = train_dataframe.columns.drop('is_attack')\n",
    "    \n",
    "    if 'multiclass' in train_dataframe.columns:\n",
    "        x_columns = x_columns.drop('multiclass')\n",
    "\n",
    "    print('X columns train')\n",
    "    print(x_columns)\n",
    "    \n",
    "    if (classification_type==1):\n",
    "        target_column = 'is_attack'\n",
    "    else:\n",
    "        target_column = 'multiclass'\n",
    "    \n",
    "    print('target test')\n",
    "    print(target_column)\n",
    "    \n",
    "    print('x split')\n",
    "    print(train_dataframe[x_columns].values)\n",
    "    \n",
    "    print('y split')\n",
    "    print(pd.get_dummies(train_dataframe[target_column]).values)\n",
    "    \n",
    "    if verbose:\n",
    "        print(f'Train validation splitting started')\n",
    "        \n",
    "    x_train, x_validation, y_train, y_validation = train_test_split(train_dataframe[x_columns].values, pd.get_dummies(train_dataframe[target_column]).values, test_size=0.20, random_state=42)\n",
    "\n",
    "    del train_dataframe\n",
    "    \n",
    "    if verbose:\n",
    "        print(f'Dataset splitting finished')\n",
    "    \n",
    "    model = def_model(x_train.shape[1], y_train.shape[1])\n",
    "    \n",
    "    monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=10, \n",
    "        verbose=1, mode='auto', restore_best_weights=True)\n",
    "    model.fit(x_train,y_train,validation_data=(x_validation,y_validation),\n",
    "        callbacks=[monitor],verbose=2,epochs=1000)\n",
    "    \n",
    "    del x_train\n",
    "    del y_train\n",
    "    del x_validation\n",
    "    del y_validation    \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models\n",
    "    \n",
    "def compute_metrics(pred, y_test):\n",
    "\n",
    "    predict_classes = np.argmax(pred,axis=1)\n",
    "    expected_classes = np.argmax(y_test,axis=1)\n",
    "    correct = metrics.accuracy_score(expected_classes,predict_classes)\n",
    "    \n",
    "    print(f\"Accuracy: {correct}\")\n",
    "    \n",
    "    recall = metrics.recall_score(expected_classes,predict_classes, average='weighted')    \n",
    "    print(f\"Recall: {recall}\")\n",
    "       \n",
    "    precision = metrics.precision_score(expected_classes,predict_classes, average='weighted')\n",
    "    print(f\"Precision: {precision}\")\n",
    "    \n",
    "    f1score = metrics.f1_score(expected_classes,predict_classes, average='weighted')\n",
    "    print(f\"F1Score: {f1score}\")\n",
    "    \n",
    "def test_data(df, classification_type, model):\n",
    "\n",
    "    target_column = 'is_attack'\n",
    "    x_columns = df.columns.drop(target_column)\n",
    "    \n",
    "    df = df.astype(int)\n",
    "    \n",
    "    x_test = df[x_columns].values\n",
    "    y_test = pd.get_dummies(df[target_column]).values\n",
    "    \n",
    "    pred = model.predict(x_test)\n",
    "    \n",
    "    compute_metrics(pred, y_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(verbose = False):\n",
    "\n",
    "    import numpy as np # used for handling numbers\n",
    "    import pandas as pd # used for handling the dataset\n",
    "    import datetime\n",
    "\n",
    "    system_time = datetime.datetime.now()\n",
    "    print(system_time.strftime(\"\\nSTART  %H:%M:%S\"))\n",
    "\n",
    "    #Importing the Dataset\n",
    "    df=pd.read_csv('C:/Dados/Nuno/MyDataset/MyDataset.txt', sep='\\x09',header=0)\n",
    "    df.dropna(inplace=True)\n",
    "\n",
    "    labelcolumn = 'label'\n",
    "    droplabelcolumn = 'detailed-label'\n",
    "    \n",
    "    df=df.drop(columns = droplabelcolumn)\n",
    "    \n",
    "    dcolumns=['id.orig_h','id.resp_h','service','duration','conn_state','history','missed_bytes','orig_ip_bytes','resp_ip_bytes','tunnel_parents']\n",
    "    df = df.drop(columns = dcolumns)\n",
    "\n",
    "    ft_col=[]\n",
    "\n",
    "    for j in range(0,len(df.columns)):\n",
    "        col = df.columns[j]\n",
    "        #print(\"Dataset column: \",col)\n",
    "        uniques = len(df[col].unique())\n",
    "        #print(\"Number of unique values = \",uniques)\n",
    "        if uniques > 1 and uniques < df.shape[0]-1:\n",
    "            ft_col.append(col)#gives us the columns that are not constant or all different\n",
    "\n",
    "    df=df[ft_col]\n",
    "    df.info()\n",
    "\n",
    "    df['prt_src'] = df['id.orig_p']\n",
    "    df['prt_dst'] = df['id.resp_p']\n",
    "    \n",
    "    df['src_port'] = df.apply (lambda row: srcprt_range(row), axis=1)\n",
    "    df = pd.concat([df,pd.get_dummies(df['src_port'],prefix=\"src_port_range\")],axis=1)\n",
    "    df.drop('src_port', axis=1, inplace=True)\n",
    "    \n",
    "    df['dst_port'] = df.apply (lambda row: dstprt_range(row), axis=1)\n",
    "    df = pd.concat([df,pd.get_dummies(df['dst_port'],prefix=\"dst_port_range\")],axis=1)\n",
    "    df.drop('dst_port', axis=1, inplace=True)\n",
    "\n",
    "    df.drop('prt_dst', axis=1, inplace = True)\n",
    "    df.drop('id.orig_p', axis=1, inplace=True)\n",
    "    df.drop('prt_src', axis=1, inplace=True)\n",
    "    df.drop('id.resp_p', axis=1, inplace=True)\n",
    "    \n",
    "    df['proto'] = np.where(df['proto']=='tcp', 6, df['proto'])\n",
    "    df['proto'] = np.where(df['proto']=='udp', 17, df['proto'])\n",
    "    df['proto'] = np.where(df['proto']=='icmp', 1, df['proto'])\n",
    "        \n",
    "    df['orig_bytes'] = np.where(df['orig_bytes']=='-', 0, df['orig_bytes'])\n",
    "    df['resp_bytes'] = np.where(df['resp_bytes']=='-', 0, df['resp_bytes'])\n",
    "\n",
    "    df['orig_bytes'] = df['orig_bytes'].astype(float)\n",
    "    df['resp_bytes'] = df['resp_bytes'].astype(float)\n",
    "    \n",
    "    df['orig_pkts'] = np.where(df['orig_pkts']=='-', 0, df['orig_pkts'])\n",
    "    df['resp_pkts'] = np.where(df['resp_pkts']=='-', 0, df['resp_pkts'])\n",
    "    \n",
    "    \n",
    "    df[df.filter(regex='orig_^',axis=1).head().columns] = zscore(df[df.filter(regex='orig_^',axis=1).head().columns])\n",
    "    df[df.filter(regex='resp_^',axis=1).head().columns] = zscore(df[df.filter(regex='resp_^',axis=1).head().columns])\n",
    "    \n",
    "    \n",
    "    df['is_attack'] = np.where(df['label']=='Malicious', 1, 0)\n",
    "    df.drop('label', axis=1, inplace=True)\n",
    "    \n",
    "    df = pd.concat([df,pd.get_dummies(df['proto'],prefix=\"proto_id\")],axis=1)\n",
    "    df.drop('proto', axis=1, inplace=True)\n",
    "        \n",
    "    df.info()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lendo os dados e preprocessando dataset\n",
    "dfN = read_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dfN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dividindo dataset entre treino e testes, e treinando o modelo\n",
    "\n",
    "verbose = True\n",
    "dfN = dfN.astype(int)\n",
    "dfN_test_dataframe = dfN.sample(frac=0.2, random_state=1337)\n",
    "dfN_train_dataframe = dfN.drop(dfN_test_dataframe.index)\n",
    "\n",
    "model = train_model(dfN_train_dataframe, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verificando o modelo nos dados de teste\n",
    "\n",
    "test_data(dfN_test_dataframe,1, model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#utilizando GanGenerator para gerar dados\n",
    "from tabgan.sampler import OriginalGenerator, GANGenerator\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "df_x_train = dfN_train_dataframe.drop(columns=['is_attack'])\n",
    "df_x_test = dfN_test_dataframe.drop(columns=['is_attack'])\n",
    "df_y_train = dfN_train_dataframe[['is_attack']]\n",
    "df_y_test = dfN_test_dataframe[['is_attack']]\n",
    "\n",
    "gen_x, gen_y = GANGenerator().generate_data_pipe(df_x_train, df_y_train,\n",
    "                                          df_x_test, deep_copy=True, only_adversarial=True, use_adversarial=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testando modelo com dados gerados\n",
    "gen_x['is_attack']=gen_y[1]\n",
    "test_data(gen_x,1,model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#utilizando adversarial-robustness-toolbox\n",
    "\n",
    "from art.attacks.evasion import FastGradientMethod\n",
    "from art.estimators.classification import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criando classificador\n",
    "\n",
    "from art.attacks.evasion import FastGradientMethod\n",
    "from art.estimators.classification import KerasClassifier\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "df_x_train = dfN_train_dataframe.drop(columns=['is_attack'])\n",
    "df_y_train = to_categorical(pd.get_dummies(dfN_train_dataframe[['is_attack']]).values)\n",
    "\n",
    "new_model = def_model(df_x_train.shape[1], df_y_train.shape[1])\n",
    "\n",
    "classifier = KerasClassifier(model=new_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#treinando o classificador\n",
    "classifier.fit(df_x_train, df_y_train, nb_epochs=20)\n",
    "\n",
    "#gerando previsoes com dados de teste\n",
    "predictions = classifier.predict(df_x_test)\n",
    "\n",
    "compute_metrics(predictions, df_y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gerando dados com FastGradientMethod\n",
    "\n",
    "attack = FastGradientMethod(estimator=classifier, eps=0.2)\n",
    "x_test_adv = attack.generate(x=df_x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dados originais\n",
    "print(df_x_test)\n",
    "\n",
    "#dados modificados - gerados por FastGradientMethod\n",
    "print(x_test_adv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# avaliando o ART classifier com dados gerados por FastGradientMethod \n",
    "predictions_adv = classifier.predict(x_test_adv)\n",
    "\n",
    "compute_metrics(predictions_adv, df_y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avaliando o modelo original com dados gerados por FastGradientMethod \n",
    "predictions_adv = model.predict(x_test_adv)\n",
    "\n",
    "compute_metrics(predictions_adv, df_y_test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
