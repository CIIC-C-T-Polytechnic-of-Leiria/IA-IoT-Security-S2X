{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e4daa6a",
   "metadata": {},
   "source": [
    "### Neural Network Model Prediction & Classification Metrics - CIIC Research - Jos√© P. Areia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd63ea2b",
   "metadata": {},
   "source": [
    "**WARNING**: Before running the Jupyter notebook, please ensure that you assign the variable **classification_type** to the desired value.\n",
    "\n",
    "Please note that <mark>the value of **classification_type** must be either 0 or 1.</mark> If you set it to 0, the model will assume that you are working with binary classification. On the other hand, if you set it to 1, the model will assume that you are working with multiclass classification.\n",
    "\n",
    "Setting the wrong value for **classification_type** can result in errors or unexpected results. Therefore, it is essential that you assign the appropriate value before running the Jupyter Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7809493f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 - Binary Classification\n",
    "# 1 - Multiclass Classification\n",
    "\n",
    "classification_type = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a1e6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow logging: OFF\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66426194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow Imports & Metric Definitions\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2 * ((precision * recall) / (precision + recall + K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950f79b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "\n",
    "if (classification_type):\n",
    "    filename = 'Testing_Multiclass.pkl'\n",
    "else:\n",
    "    filename = 'Testing_Binary.pkl'\n",
    "\n",
    "\n",
    "dataset_directory = 'Saved_Datasets/NetSim'\n",
    "dataset_local = os.path.join(dataset_directory, filename)\n",
    "\n",
    "# Loading Test Fraction \n",
    "with open(dataset_local, 'rb') as f:\n",
    "    x_test, y_test = pkl.load(f)\n",
    "\n",
    "print(f'[DONE] Loading Test Fraction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3841e807",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "if (classification_type):\n",
    "    filename = 'Model_Multiclass.h5'\n",
    "else:\n",
    "    filename = 'Model_Binary.h5'\n",
    "\n",
    "model_directory = 'Saved_Models/NetSim'\n",
    "model_local = os.path.join(model_directory, filename)\n",
    "\n",
    "# Loading Training Model \n",
    "model = load_model(model_local, custom_objects = { 'f1_m': f1_m })\n",
    "\n",
    "print(f'[DONE] Loading Training Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49283a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe34398",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "\n",
    "# Metrics for the classification\n",
    "def compute_metrics(pred, y_test):\n",
    "    predict_classes = np.argmax(pred, axis = 1)\n",
    "    expected_classes = np.argmax(y_test, axis = 1)\n",
    "    \n",
    "    correct = metrics.accuracy_score(expected_classes, predict_classes)\n",
    "    print(f\"Accuracy: {correct}\")\n",
    "    \n",
    "    recall = metrics.recall_score(expected_classes, predict_classes, average = 'weighted')    \n",
    "    print(f\"Recall: {recall}\")\n",
    "       \n",
    "    precision = metrics.precision_score(expected_classes, predict_classes, average = 'weighted')\n",
    "    print(f\"Precision: {precision}\")\n",
    "    \n",
    "    f1score = metrics.f1_score(expected_classes, predict_classes, average = 'weighted')\n",
    "    print(f\"F1Score: {f1score}\")\n",
    "    \n",
    "compute_metrics(pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de74b9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Confusion Matrix\n",
    "predict_classes = np.argmax(pred, axis = 1)\n",
    "expected_classes = np.argmax(y_test, axis = 1)    \n",
    "    \n",
    "cm = confusion_matrix(expected_classes, predict_classes)\n",
    "cmd = ConfusionMatrixDisplay(cm)\n",
    "\n",
    "# Plot size\n",
    "fig, ax = plt.subplots(figsize = (6, 6))\n",
    "\n",
    "cmd.plot(ax = ax)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
